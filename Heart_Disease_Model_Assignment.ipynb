{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook builds on the exploratory data analysis conducted previously, and experiments with multiple machine learning models in an attempt to maximize accuracy. The models we apply will be from the Scikit-Learn library.\n",
    "\n",
    "The original dataset and an explanation of each of the features is available on Kaggle [here](https://www.kaggle.com/ronitf/heart-disease-uci)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "heart_data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat the data cleaning steps we took in our EDA notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = heart_data.drop([85, 92, 158, 163, 164, 251], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 14)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Since we're predicting a classification label, an obvious model choice to start with is Logistic Regression. First, let's assign our X and y. We'll also assign a random state variable to maintain consistency as we run our code repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_data.drop(columns=['target'])\n",
    "y = heart_data['target']\n",
    "r_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the train_test_split function from scikit-learn and set our test size to 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the size of X_train to ensure that it took 70% of our rows, as well as the shape of X_test. Together, the number of rows should sum to 297, the shape of our original data set after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 13)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 13)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Next, we'll create and fit our Logistic Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = LogisticRegression(random_state=r_state)\n",
    "my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been trained on the data, we'll predict the labels of our test set. The variable we create, y_pred, will hold an array of 90 categorical labels (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = my_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model using accuracy, which is the most straightforward measure of success and a good place to start. We'll use scikit-learn's .score() function and compare our test labels and our model's prediction labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_score = my_model.score(X_test, y_test)\n",
    "my_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Without any additional feature engineering, we can predict with about 84% accuracy whether or not a subject will have heart disease given a set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Let's try running our model again but only using the feature columns that have at least a +/-0.3 correlation with our target. Based on the .corr() we did in our EDA notebook, that would be:\n",
    "- cp\n",
    "- thalach\n",
    "- exang\n",
    "- oldpeak\n",
    "- slope\n",
    "- ca\n",
    "- thal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_features = ['cp', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "X = heart_data[subset_features]\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_2 = LogisticRegression(random_state=r_state)\n",
    "my_model_2.fit(X_train, y_train)\n",
    "y_pred = my_model_2.predict(X_test)\n",
    "my_model_2_score = my_model_2.score(X_test, y_test)\n",
    "my_model_2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So dropping some of the less correlated features improved our accuracy score a little bit, but not dramatically; we achieved 87% accuracy. \n",
    "\n",
    "## Model 3\n",
    "What if we narrow down our features even further, and only use the columns that have at least a +/-0.4 correlation with our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_features = ['cp', 'exang', 'oldpeak', 'ca']\n",
    "X = heart_data[subset_features]\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_3 = LogisticRegression(random_state=r_state)\n",
    "my_model_3.fit(X_train, y_train)\n",
    "y_pred = my_model_3.predict(X_test)\n",
    "my_model_3_score = my_model_3.score(X_test, y_test)\n",
    "my_model_3_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That made our accuracy score decrease to 78%! We are eliminating too much feature data now. Let's try some other methods.\n",
    "\n",
    "## Model 4\n",
    "I'd like to see what happens when we apply one-hot encoding to our categorical features. Since they're not scaled/ranked measurements, I think it's possible that the model is misinterpretting their meaning. We'll use the pandas function .get_dummies() applied to our categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>cp_0</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>ca_0</th>\n",
       "      <th>ca_1</th>\n",
       "      <th>ca_2</th>\n",
       "      <th>ca_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>150</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>187</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>172</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>178</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>163</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  trestbps  chol  thalach  oldpeak  target  sex_0  sex_1  cp_0  cp_1  \\\n",
       "0   63       145   233      150      2.3       1      0      1     0     0   \n",
       "1   37       130   250      187      3.5       1      0      1     0     0   \n",
       "2   41       130   204      172      1.4       1      1      0     0     1   \n",
       "3   56       120   236      178      0.8       1      0      1     0     1   \n",
       "4   57       120   354      163      0.6       1      1      0     1     0   \n",
       "\n",
       "   ...  slope_1  slope_2  ca_0  ca_1  ca_2  ca_3  thal_0  thal_1  thal_2  \\\n",
       "0  ...        0        0     1     0     0     0       0       1       0   \n",
       "1  ...        0        0     1     0     0     0       0       0       1   \n",
       "2  ...        0        1     1     0     0     0       0       0       1   \n",
       "3  ...        0        1     1     0     0     0       0       0       1   \n",
       "4  ...        0        1     1     0     0     0       0       0       1   \n",
       "\n",
       "   thal_3  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied_data = pd.get_dummies(heart_data, columns = \n",
    "                              ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])\n",
    "dummied_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates many more columns than we had before, since each previous column is expanded to the number of categories it includes. We now have 31 columns of data. Let's run our Logistic Regression model again using our dummied data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dummied_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_4 = LogisticRegression(random_state=r_state)\n",
    "my_model_4.fit(X_train, y_train)\n",
    "y_pred = my_model_4.predict(X_test)\n",
    "my_model_4_score = my_model_4.score(X_test, y_test)\n",
    "my_model_4_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Model 4 gives us the exact same accuracy measure as Model 1: 84%.\n",
    "\n",
    "## Model 5\n",
    "What if we continue with one-hot encoding, but only utilize the features that have +/-0.3 correlation coefficients, as we did in Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied_data = pd.get_dummies(heart_data, columns = \n",
    "                              ['cp', 'exang', 'slope', 'ca', 'thal'])\n",
    "dummied_data = dummied_data.drop(columns=['age', 'sex', 'trestbps', 'chol', 'fbs', 'restecg', 'target'])\n",
    "X = dummied_data\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_5 = LogisticRegression(random_state=r_state)\n",
    "my_model_5.fit(X_train, y_train)\n",
    "y_pred = my_model_5.predict(X_test)\n",
    "my_model_5_score = my_model_5.score(X_test, y_test)\n",
    "my_model_5_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Model 5 gives us the exact same accuracy measure as Model 2, at 87%! I think it's safe to say that one-hot encoding has no influence on this data set when using a Logistic Regression model.\n",
    "\n",
    "## Nearest Neighbors\n",
    "Let's try a machine learning model other than Logistic Regression next. Scikit Learn has a Nearest Neighbors Classification model. As a baseline, we'll use our full data set, without applying one-hot encoding.\n",
    "\n",
    "## Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888888888888889"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_6 = KNeighborsClassifier(n_neighbors=15)\n",
    "my_model_6.fit(X_train, y_train)\n",
    "y_pred = my_model_6.predict(X_test)\n",
    "my_model_6_score = my_model_6.score(X_test, y_test)\n",
    "my_model_6_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did a quick experiment with the number of n_neighbors to use, and 15 seems to give us the best result at 69% accuracy, which still isn't very good.\n",
    "\n",
    "## Model 7\n",
    "Let's try the KNN model after applying one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888888888888889"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummied_data = pd.get_dummies(heart_data, columns = \n",
    "                              ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])\n",
    "X = dummied_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_7 = KNeighborsClassifier(n_neighbors=15)\n",
    "my_model_7.fit(X_train, y_train)\n",
    "y_pred = my_model_7.predict(X_test)\n",
    "my_model_7_score = my_model_7.score(X_test, y_test)\n",
    "my_model_7_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently one-hot encoding doesn't have any effect when utilizing the KNN model either; we've again achieved an accuracy score of 69%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Scikit Learn also has a Decision Tree Classification model. As a baseline, we'll again use our full data set, without applying one-hot encoding.\n",
    "\n",
    "## Model 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7444444444444445"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_8 = DecisionTreeClassifier(random_state=r_state)\n",
    "my_model_8.fit(X_train, y_train)\n",
    "y_pred = my_model_8.predict(X_test)\n",
    "my_model_8_score = my_model_8.score(X_test, y_test)\n",
    "my_model_8_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree model gives us an accuracy score of about 74%, which is still far below our earlier logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "## Model 9\n",
    "Our ninth model will explore the Support Vector Machine model in the Scikit-Learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_9 = svm.SVC(kernel='linear')\n",
    "my_model_9.fit(X_train, y_train)\n",
    "y_pred = my_model_9.predict(X_test)\n",
    "my_model_9_score = my_model_9.score(X_test, y_test)\n",
    "my_model_9_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, at least our accuracy score has crept back into the 80-something percentile, more in range with our initial logistic regression model.\n",
    "\n",
    "## Gaussian Naive Bayes\n",
    "## Model 10\n",
    "Our tenth model will use the Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_10 = GaussianNB()\n",
    "my_model_10.fit(X_train, y_train)\n",
    "y_pred = my_model_10.predict(X_test)\n",
    "my_model_10_score = my_model_10.score(X_test, y_test)\n",
    "my_model_10_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian Naive Bayes model has yielded us 80% accuracy.\n",
    "\n",
    "## Random Forest Classifier\n",
    "## Model 11\n",
    "Lastly, we'll build and train a Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_data.drop(columns=['target'])\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_11 = RandomForestClassifier()\n",
    "my_model_11.fit(X_train, y_train)\n",
    "y_pred = my_model_11.predict(X_test)\n",
    "my_model_11_score = my_model_11.score(X_test, y_test)\n",
    "my_model_11_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy score of 82% rounds out our experimental models.\n",
    "\n",
    "## Review and Summary\n",
    "Let's take a moment to visualize the accuracy scores of the many models we've built. First we'll create a pandas dataframe of the accuracy scores so that we can pass that data into our plotting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_df = pd.DataFrame(\n",
    "    {\n",
    "    'Model 1': [my_model_score], \n",
    "    'Model 2': [my_model_2_score], \n",
    "    'Model 3': [my_model_3_score],\n",
    "    'Model 4': [my_model_4_score],\n",
    "    'Model 5': [my_model_5_score],\n",
    "    'Model 6': [my_model_6_score],\n",
    "    'Model 7': [my_model_7_score],\n",
    "    'Model 8': [my_model_8_score],\n",
    "    'Model 9': [my_model_9_score],\n",
    "    'Model 10': [my_model_10_score],\n",
    "    'Model 11': [my_model_11_score]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_dims = (15, 12)\n",
    "fig = plt.subplots(figsize=fig_dims)\n",
    "plt.ylabel('Accuracy Score')\n",
    "sns.barplot(data=accuracy_score_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Models 2 and 5 had the highest accuracy scores (as you'll recall, the scores of these two models were the same, as we used the exact same parameters excepting Model 5 was one-hot encoded). So Logistic Regression was the highest performer for this dataset; 87% accuracy is a decent measure. Let's take model 2 and explore it a little further.\n",
    "\n",
    "Since we've built so many models in this notebook and reused variable names, let's rebuild Model 2 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robineastwood/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "subset_features = ['cp', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "X = heart_data[subset_features]\n",
    "# our y variable will not change.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=r_state)\n",
    "my_model_2 = LogisticRegression(random_state=r_state)\n",
    "my_model_2.fit(X_train, y_train)\n",
    "y_pred = my_model_2.predict(X_test)\n",
    "my_model_2_score = my_model_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification report will allow us to see our most important metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "   0=heart disease       0.88      0.79      0.83        38\n",
      "1=no heart disease       0.86      0.92      0.89        52\n",
      "\n",
      "          accuracy                           0.87        90\n",
      "         macro avg       0.87      0.86      0.86        90\n",
      "      weighted avg       0.87      0.87      0.87        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=('0=heart disease', '1=no heart disease')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break these numbers down.\n",
    "**Precision** tells us what percentage of our predictions were correct, looking at true positives as a percentage of all positives. For target 0 we predicted correctly 88% of the time, for target 1 we predicted correctly 86% of the time.\n",
    "**Recall** tells us the percentage of positive cases we caught. For target 0 we caught 79% of cases, for target 1 we caught 92% of cases. That means we missed 21% of cases where subjects did have heart disease, assigning them a false negative label.\n",
    "The **F1 score** is a formulaic measure of precision and recall together.\n",
    "\n",
    "**Accuracy** is the most straightforward metric and the one we've been primarily evaluating thus far. It is a measure of our correct predictions as a percentage of all predictions made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a confusion matrix will give us a tabular visual on the true/false positives/negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  8]\n",
      " [ 4 48]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 30 True Positives\n",
    "- 4 False Negatives\n",
    "- 8 False Positives\n",
    "- 48 True Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrix)\n",
    "labels = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(confusion_df, \n",
    "            annot=labels, \n",
    "            fmt='',\n",
    "            annot_kws={\"size\": 20},\n",
    "            cmap='Blues'\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
